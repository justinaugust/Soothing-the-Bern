{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling using TFIDF on `'body'`, SVC & Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tokenizer.tokenizer import RedditTokenizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize  \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "from my_tools.pipes_grids import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('datasets/data_submissions.csv')\n",
    "except:\n",
    "    df = pd.read_csv('https://www.dropbox.com/s/eh48hdw4af7tjc3/data_submissions.csv?dl=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/df_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the pipeline and gridsearch here to be used for this round of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(\n",
    "    [('tvec',TfidfVectorizer(), 'body')],\n",
    "    remainder='passthrough',\n",
    "    sparse_threshold=0.3,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('ct',ct),\n",
    "    ('svc',SVC(gamma='scale'))\n",
    "\n",
    "])\n",
    "\n",
    "pipe_params = {\n",
    "    'ct__tvec__tokenizer' : [None,RedditIt(),LemmaTokenizer()],\n",
    "    'ct__tvec__ngram_range' : [(1,1),(1,2)],\n",
    "    'ct__tvec__max_features' : [None],\n",
    "    'ct__tvec__min_df' : [.01,.02],\n",
    "    'ct__tvec__max_df' : [.9,1.0],\n",
    "    'ct__tvec__stop_words' : [nltk_stops],\n",
    "    'svc__C' : np.logspace(-2,2, 30),\n",
    "    'svc__kernel' : ['linear','rbf','poly'],\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, # what object are we optimizing?\n",
    "                  pipe_params, # what parameters values are we searching?\n",
    "                  cv=3,# 3-fold cross-validation.\n",
    "                 n_jobs = -1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions to automate the model fitting, gridsearch & score outputs\n",
    "see [`my_tools/pipes_grids.py`](my_tools/pipes_grids.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation and Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justinaugust/.conda/envs/dsi/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    }
   ],
   "source": [
    "X = df[['body']]\n",
    "y = df['is_2016']\n",
    "model_base = model_go(X=X,\n",
    "        y=y,\n",
    "      gridsearch=gs)\n",
    "model_base[0].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['body','vaderSentiment']]\n",
    "y = df['is_2016']\n",
    "model_vader = model_go(X=X,\n",
    "        y=y,\n",
    "        gridsearch=gs)\n",
    "model_vader[0].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['body','senti_score']]\n",
    "y = df['is_2016']\n",
    "model_sentiscore = model_go(X=X,\n",
    "        y=y,\n",
    "        gridsearch=gs)\n",
    "model_sentiscore[0].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-dsi] *",
   "language": "python",
   "name": "conda-env-.conda-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
